#' Create a worker object for use as a worker with master objects generated by [PoissonRegressionMaster()]
#' @description `PoissonRegressionWorker` objects are worker objects at each site of
#' a distributed univariate linear model computation
#'
#' @docType class
#' @seealso `PoissonRegressionMaster` which goes hand-in-hand with this object
#' @importFrom R6 R6Class
#' @section Methods:
#' \describe{
#'   \item{`PoissonRegressionWorker$new(defn, data, stateful=TRUE)`}{Create a new PoissonRegressionWorker instance
#'         object using formula and data. The stateful flag indicates whether the object
#'         state is to be saved between iterations}
#'   \item{`logLik(beta, ...)`}{Compute the partial log likelihood for the local data
#'         for the input parameter vector beta. The return value is the negative value of the log likelihood,
#'         `gradient` contains the score vector, and `hessian` contains
#'         the estimated hessian matrix}
#'   \item{`kosher()`}{Check if inputs and state of object are sane. For future use}
#'   \item{`getP()`}{Returns the dimension of the parameter `vector`}
#'   \item{`getStateful()`}{Returns `TRUE` if object is stateful, else `FALSE`}
#' }
#'
#' @export
#' @format An [R6::R6Class()] generator object
PoissonRegressionWorker <- R6Class(
  "PoissonRegressionWorker",
  private = list(
    defn = NA 
    , stateful = FALSE
    , p = NA
    , data = list()
    , model_X = NULL
    , model_Y = NULL
    , result = list()
  ),
  public = list(
    initialize = function(defn, data, stateful=TRUE) {
      private$defn <- defn
      private$stateful <- stateful
      private$data <- data
      formula <- as.formula(defn$formula)
      model <- model.frame(formula, data=data)
      private$model_X <- model.matrix(formula, data=data)
      private$model_Y <- model.response(model)
      private$p <- ncol(private$model_X)
      stopifnot(self$kosher())
    } , getP = function(...) {
      private$p
    },  getStateful = function() {
      private$stateful
    }, logLik = function(beta, ...) {
      # return the negative log likelihood so it can be minimized by optim
      lambda <- exp(beta%*%t(private$model_X)) # calculate parameters
      ll <- -sum(dpois(private$model_Y, lambda, log=TRUE)) # get negative log likelihood
      ll
    }, kosher = function() {
      ## add sanity checks (?)
      TRUE
    })
)

#' Create a master object to control worker objects generated by [PoissonRegressionWorker()]
#' @description `PoissonRegressionMaster` objects instantiate and run a distributed Cox model
#' computation fit
#' @docType class
#' @seealso `PoissonRegressionWorker` which generates objects matched to such a master object
#' @importFrom R6 R6Class
#' @section Methods:
#'
#' \describe{
#'   \item{`PoissonRegressionMaster$new(defn, data, debug=FALSE)`}{Create a new
#'         PoissonRegressionMaster object using the defn and data. The debug flag is useful for
#'         debugging}
#'   \item{`logLik(beta, ...)`}{Compute the partial log likelihood for all the data
#'         by aggregating the values at each site. The return value is numeric scalar with
#'         two attributes: `gradient` contains the score vector, and `hessian`
#'         contains the estimated hessian matrix}
#'   \item{`sumRSS(beta0, beta1, ...)`}{Compute the sum of the squared residuals for all the data
#'         by aggregating the values at each site. The return value is numeric scalar which is the sum of the squared residuals across all sites.}
#'   \item{`addSite(name, url = NULL, worker = NULL)`}{Add a worker
#'         site for participating in the distributed computation. Exactly one of `url` or `worker` should be specified}
#'   \item{`var(beta, ...)`}{Compute the variance of the parameter vector beta}
#'   \item{`kosher()`}{Check if inputs and state of object are sane. For future use}
#'   \item{`getP()`}{Returns the dimension of the parameter vector}
#'   \item{`run(control)`}{Run the fitting iterations and save the result using control object}
#'   \item{`summary()`}{Return a summary data frame columns for `coef`, `exp(coef)`,
#'         standard error, z-score, and p-value for each parameter in the model following
#'         the same format as the `survival` package}
#' }
#'
#' @export
#' @format An [R6::R6Class()] generator object
PoissonRegressionMaster <- R6Class(
  "PoissonRegressionMaster",
  private = list(
    defn = NA
    , dry_run = FALSE
    , sites = list()
    # , p = NA
    , mapFn = function(site, beta) {
      payload <- list(objectId = site$instanceId,
                      method = "sumRSS",
                      beta = beta)
      q <- POST(.makeOpencpuURL(urlPrefix=site$url, fn="executeMethod"),
                body = toJSON(payload),
                add_headers("Content-Type" = "application/json"),
                config=getConfig()$sslConfig
      )
      ## Should really examine result here.
      .deSerialize(q)
    }, result = list()
    , debug = FALSE
  ),
  public = list(
    initialize = function(defn, debug = FALSE) {
      'Initialize the object with a defn and flag'
      private$defn <- defn
      private$debug <- debug
      stopifnot(self$kosher())
    }, kosher = function() {
      ' Check for sanity'
      TRUE
    }, logLik = function(beta) {
      'Calculate the log likelihood'
      debug <- private$debug
      if (debug) {
        print("beta")
        print(beta)
      }
      sites <- private$sites
      n <- length(sites)
      if (private$dry_run) {
        mapFn <- function(x, arg) x$worker$logLik(arg)
      } else {
        mapFn <- private$mapFn
      }
      results <- Map(mapFn, sites, rep(list(beta), n))
      value <- Reduce(f = sum, results)
      if (debug) {
        print("value")
        print(value)
      }
      value # returns the sum of the residual sum of squares for all sites
    }, addSite = function(name, url = NULL, worker = NULL) {
      'Add a site identified by url with a name'
      ## critical section start
      ## This is the time to cache "p" and check it
      ## against all added sites
      ## Only one of url/worker should be non-null
      stopifnot(is.null(url) || is.null(worker))
      n <- length(private$sites)
      if (is.null(url)) {
        private$dry_run <- private$dry_run || TRUE
        private$sites[[n+1]] <- list(name = name, worker = worker)
      } else {
        localhost <- (grepl("^http://localhost", url) ||
                        grepl("^http://127.0.0.1", url))
        private$sites[[n+1]] <- list(name = name, url = url,
                                     localhost = localhost,
                                     dataFileName = if (localhost) paste0(name, ".rds") else NULL)
      }
      ## critical section end
    }, getResult = function(){
      private$result
    }, run = function(control=NULL) {
      'Run estimation'
      dry_run <- private$dry_run
      debug <- private$debug
      defn <- private$defn
      if (debug) {
        print("run(): checking worker object creation")
      }
      if (dry_run) {
        ## Workers have already been created and passed
        sites <- private$sites
        pVals <- sapply(sites, function(x) x$worker$getP())
        if(debug) {
          print("Checking pVals:")
          print(pVals)
        }
      } else {
        ## Create an instance Id
        instanceId <- generateId(object=list(Sys.time(), self))
        ## Augment each site with object instance ids
        private$sites <- sites <-
          lapply(private$sites,
                 function(x) list(name = x$name,
                                  url = x$url,
                                  localhost = x$localhost,
                                  dataFileName = x$dataFileName,
                                  instanceId = if (x$localhost) x$name else instanceId))
        ## Create instance objects
        sitesOK <- sapply(
          sites,
          function(x) {
            payload <- if (is.null(x$dataFileName)) {
              list(defnId = defn$id, instanceId = x$instanceId)
            } else {
              list(defnId = defn$id, instanceId = x$instanceId,
                   dataFileName = x$dataFileName)
            }
            q <- POST(url = .makeOpencpuURL(urlPrefix=x$url, fn="createInstanceObject"),
                      body = toJSON(payload),
                      add_headers("Content-Type" = "application/json"),
                      config=getConfig()$sslConfig
            )
            .deSerialize(q)
          })
        
        ## I am not checking the value of p here; I do it later below
        if (!all(sitesOK)) {
          warning("run():  Some sites did not respond successfully!")
          private$sites <- sites <- sites[which(sitesOK)]  ## Only use sites that created objects successfully.
        }
        ## stop if no sites
        if (debug) {
          print("run(): checking p")
        }
        pVals <- sapply(
          sites,
          function(x) {
            payload <- list(objectId = x$instanceId, method = "getP")
            if(debug){
              print("Printing pVal payload: ")
              print(payload)
            }
            q <- POST(.makeOpencpuURL(urlPrefix=x$url, fn="executeMethod"),
                      body = toJSON(payload),
                      add_headers("Content-Type" = "application/json"),
                      config=getConfig()$sslConfig
            )
            .deSerialize(q)
          })
      }
      if (debug) {
        print("Printing pVals:")
        print(pVals)
      }
      if (any(pVals != pVals[1])) {
        stop("run(): Heterogeneous sites! Stopping!")
      }
      p <- pVals[1]
      if (debug) {
        print(paste("p is ", p))
      }
      
      ## TODO: solve for the log likelihood at each site
      control <- list(iter.max=1000, eps=0)
      ### Call to optim to find parameters
      prevBeta <- rep(0, p) # define the first set of betas to use, default to all 0s
      fit <- optim(prevBeta 
                   , fn = self$logLik
                   , hessian = TRUE)
      
      # saving the result
      private$result <- result <- list(beta = fit$par
                                       , iter = fit$counts
                                       , hessian = fit$hessian
                                       , returnCode = fit$convergence)
      
      if (!dry_run) {
        if (debug) {
          print("run(): checking worker object cleanup")
        }
        sitesOK <- sapply(
          sites,
          function(x) {
            payload <- list(instanceId = x$instanceId)
            q <- POST(url = .makeOpencpuURL(urlPrefix=x$url, fn="destroyInstanceObject"),
                      body = toJSON(payload),
                      add_headers("Content-Type" = "application/json"),
                      config=getConfig()$sslConfig
            )
            .deSerialize(q)
          })
        if (!all(sitesOK)) {
          warning("run():  Some sites did not clean up successfully!")
        }
      }
      ## Should probably clean up sites list and remove instanceId too...
      result
    },
    summary = function() {
      'Run the summary'
      result <- private$result
      if (length(result) == 0) {
        warning("Calculating...")
        run()
        result <- private$result
      }
      
      hessianInv <- solve(result$hessian)
      se <- sqrt(diag(hessianInv))
      eCoef <- exp(result$beta)
      
      # change to provide the se, z score, and p-value for the poisson regression (this is copied from cox)
      d <- as.data.frame(t(sapply(seq.int(length(result$beta)),
                                  function(i) {
                                    coef <- result$beta[i]
                                    eCoef <- exp(coef)
                                    se <- sqrt(diag(result$hessian))
                                    z <- coef / se
                                    pValue <- 2*pnorm(z, lower.tail=(z <= 0))
                                    c("coef"=coef, "exp(coef)"=eCoef, "se(coef)"=se, z=z, p=pValue)
                                  })))
      d
    }
  )
)


